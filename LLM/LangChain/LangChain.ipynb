{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5efcd90-135c-4a23-9fa6-5537abff6c29",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: langchain-openai in /root/miniconda3/envs/myconda/lib/python3.10/site-packages (0.3.10)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.48 in /root/miniconda3/envs/myconda/lib/python3.10/site-packages (from langchain-openai) (0.3.48)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.68.2 in /root/miniconda3/envs/myconda/lib/python3.10/site-packages (from langchain-openai) (1.68.2)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /root/miniconda3/envs/myconda/lib/python3.10/site-packages (from langchain-openai) (0.9.0)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /root/miniconda3/envs/myconda/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.48->langchain-openai) (0.3.18)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /root/miniconda3/envs/myconda/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.48->langchain-openai) (8.2.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /root/miniconda3/envs/myconda/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.48->langchain-openai) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /root/miniconda3/envs/myconda/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.48->langchain-openai) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /root/miniconda3/envs/myconda/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.48->langchain-openai) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /root/miniconda3/envs/myconda/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.48->langchain-openai) (4.12.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /root/miniconda3/envs/myconda/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.48->langchain-openai) (2.10.6)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /root/miniconda3/envs/myconda/lib/python3.10/site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /root/miniconda3/envs/myconda/lib/python3.10/site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /root/miniconda3/envs/myconda/lib/python3.10/site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /root/miniconda3/envs/myconda/lib/python3.10/site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (0.9.0)\n",
      "Requirement already satisfied: sniffio in /root/miniconda3/envs/myconda/lib/python3.10/site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /root/miniconda3/envs/myconda/lib/python3.10/site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (4.66.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /root/miniconda3/envs/myconda/lib/python3.10/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in /root/miniconda3/envs/myconda/lib/python3.10/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2.31.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /root/miniconda3/envs/myconda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.68.2->langchain-openai) (1.2.2)\n",
      "Requirement already satisfied: idna>=2.8 in /root/miniconda3/envs/myconda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.68.2->langchain-openai) (3.4)\n",
      "Requirement already satisfied: certifi in /root/miniconda3/envs/myconda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain-openai) (2023.7.22)\n",
      "Requirement already satisfied: httpcore==1.* in /root/miniconda3/envs/myconda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain-openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /root/miniconda3/envs/myconda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain-openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /root/miniconda3/envs/myconda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.48->langchain-openai) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /root/miniconda3/envs/myconda/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.48->langchain-openai) (3.10.16)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /root/miniconda3/envs/myconda/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.48->langchain-openai) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /root/miniconda3/envs/myconda/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.48->langchain-openai) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /root/miniconda3/envs/myconda/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.48->langchain-openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /root/miniconda3/envs/myconda/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.48->langchain-openai) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /root/miniconda3/envs/myconda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.2.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/miniconda3/envs/myconda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (1.26.16)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd53bb09-d8e3-4aed-9f17-cd950faa1bc8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: openai in /root/miniconda3/envs/myconda/lib/python3.10/site-packages (1.68.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /root/miniconda3/envs/myconda/lib/python3.10/site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /root/miniconda3/envs/myconda/lib/python3.10/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /root/miniconda3/envs/myconda/lib/python3.10/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /root/miniconda3/envs/myconda/lib/python3.10/site-packages (from openai) (0.9.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /root/miniconda3/envs/myconda/lib/python3.10/site-packages (from openai) (2.10.6)\n",
      "Requirement already satisfied: sniffio in /root/miniconda3/envs/myconda/lib/python3.10/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /root/miniconda3/envs/myconda/lib/python3.10/site-packages (from openai) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /root/miniconda3/envs/myconda/lib/python3.10/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /root/miniconda3/envs/myconda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
      "Requirement already satisfied: idna>=2.8 in /root/miniconda3/envs/myconda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: certifi in /root/miniconda3/envs/myconda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2023.7.22)\n",
      "Requirement already satisfied: httpcore==1.* in /root/miniconda3/envs/myconda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /root/miniconda3/envs/myconda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /root/miniconda3/envs/myconda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /root/miniconda3/envs/myconda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc164da-4edc-4a7c-a5b9-f2481206092f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models.base import BaseChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "511b58d8-718a-4fc5-b274-73b43db0d8a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# åˆå§‹åŒ–LLM\n",
    "llm = BaseChatOpenAI(\n",
    "    model='deepseek-chat',  # ä½¿ç”¨DeepSeekèŠå¤©æ¨¡å‹\n",
    "    openai_api_key='sk-b6de1e42df724c84b39a309c5788569d',  # æ›¿æ¢ä¸ºä½ çš„APIæ˜“APIå¯†é’¥\n",
    "    openai_api_base='https://api.deepseek.com',  # APIæ˜“çš„ç«¯ç‚¹\n",
    "    max_tokens=1024  # è®¾ç½®æœ€å¤§ç”Ÿæˆtokenæ•°\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af0d4ca-15aa-48eb-8066-07ddc0641767",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = llm.invoke(\"è¯·ä»‹ç»ä¸€ä¸‹ä¸­å›½çš„äººå·¥æ™ºèƒ½å‘å±•ç°çŠ¶\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e635200-33f5-41d7-8185-017230e42e48",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "é¦™æ¸¯ä¸­æ–‡å¤§å­¦ï¼ˆæ·±åœ³ï¼‰ï¼ˆThe Chinese University of Hong Kong, Shenzhenï¼Œç®€ç§°CUHK-Shenzhenï¼‰æ˜¯ä¸€æ‰€ç»æ•™è‚²éƒ¨æ‰¹å‡†ï¼Œç”±é¦™æ¸¯ä¸­æ–‡å¤§å­¦ä¸æ·±åœ³å¤§å­¦åˆä½œåˆ›åŠçš„å…·æœ‰ç‹¬ç«‹æ³•äººèµ„æ ¼çš„ä¸­å¤–åˆä½œå¤§å­¦ã€‚å­¦æ ¡ä½äºå¹¿ä¸œçœæ·±åœ³å¸‚é¾™å²—åŒºï¼Œäº2014å¹´æ­£å¼è®¾ç«‹ï¼Œç§‰æ‰¿é¦™æ¸¯ä¸­æ–‡å¤§å­¦çš„å­¦æœ¯ä¼ ç»Ÿå’ŒåŠå­¦ç†å¿µï¼Œè‡´åŠ›äºåŸ¹å…»å…·æœ‰å›½é™…è§†é‡ã€åˆ›æ–°ç²¾ç¥å’Œè·¨æ–‡åŒ–ç†è§£èƒ½åŠ›çš„é«˜ç´ è´¨äººæ‰ã€‚\n",
      "\n",
      "### å­¦æ ¡ç‰¹è‰²\n",
      "1. **å›½é™…åŒ–æ•™è‚²**ï¼šé‡‡ç”¨å…¨è‹±æ–‡æ•™å­¦ï¼Œå¸ˆèµ„å›¢é˜Ÿæ¥è‡ªå…¨çƒçŸ¥åé«˜æ ¡ï¼Œè¯¾ç¨‹è®¾ç½®ä¸å›½é™…æ¥è½¨ï¼Œæä¾›ä¸°å¯Œçš„å›½é™…äº¤æµæœºä¼šã€‚\n",
      "2. **ä¹¦é™¢åˆ¶**ï¼šç»§æ‰¿é¦™æ¸¯ä¸­æ–‡å¤§å­¦çš„ä¹¦é™¢ä¼ ç»Ÿï¼Œè®¾æœ‰å¤šä¸ªä¹¦é™¢ï¼Œæ³¨é‡å…¨äººæ•™è‚²ï¼Œä¿ƒè¿›å­¦ç”Ÿå…¨é¢å‘å±•ã€‚\n",
      "3. **å­¦ç§‘è®¾ç½®**ï¼šæ¶µç›–ç†å·¥ã€ç»ç®¡ã€äººæ–‡ç¤¾ç§‘ç­‰é¢†åŸŸï¼Œå¼€è®¾å¤šä¸ªæœ¬ç§‘ã€ç¡•å£«åŠåšå£«é¡¹ç›®ï¼Œå¦‚è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯ã€é‡‘èå·¥ç¨‹ã€æ•°æ®ç§‘å­¦ç­‰ã€‚\n",
      "4. **ç ”ç©¶å¯¼å‘**ï¼šæ³¨é‡ç§‘ç ”åˆ›æ–°ï¼Œè®¾ç«‹å¤šä¸ªç ”ç©¶é™¢å’Œå®éªŒå®¤ï¼Œä¸å›½å†…å¤–é«˜æ ¡åŠä¼ä¸šåˆä½œå¼€å±•å‰æ²¿ç ”ç©¶ã€‚\n",
      "5. **åœ°ç†ä½ç½®**ï¼šåœ°å¤„æ·±åœ³ï¼Œäº«æœ‰ç²¤æ¸¯æ¾³å¤§æ¹¾åŒºçš„åŒºä½ä¼˜åŠ¿ï¼Œä¾¿äºå­¦ç”Ÿå®ä¹ å’Œå°±ä¸šã€‚\n",
      "\n",
      "### å­¦æœ¯ä¸ç”Ÿæ´»\n",
      "- **å¸ˆèµ„åŠ›é‡**ï¼šæ•™å¸ˆå¤§å¤šå…·æœ‰æµ·å¤–é¡¶å°–å¤§å­¦åšå£«å­¦ä½æˆ–ç ”ç©¶ç»å†ã€‚\n",
      "- **æ ¡å›­è®¾æ–½**ï¼šç°ä»£åŒ–æ ¡å›­é…å¤‡å…ˆè¿›çš„æ•™å­¦ã€ç§‘ç ”å’Œç”Ÿæ´»è®¾æ–½ï¼Œç¯å¢ƒä¼˜ç¾ã€‚\n",
      "- **å°±ä¸šä¸æ·±é€ **ï¼šæ¯•ä¸šç”Ÿå°±ä¸šç‡é«˜ï¼Œå¤šæ•°è¿›å…¥çŸ¥åä¼ä¸šæˆ–æµ·å¤–åæ ¡æ·±é€ ã€‚\n",
      "\n",
      "### åˆä½œä¸äº¤æµ\n",
      "ä¸å…¨çƒå¤šæ‰€é«˜æ ¡å»ºç«‹åˆä½œå…³ç³»ï¼Œæä¾›äº¤æ¢ç”Ÿã€è”åˆç ”ç©¶ç­‰é¡¹ç›®ï¼Œå¢å¼ºå­¦ç”Ÿçš„å›½é™…ç«äº‰åŠ›ã€‚\n",
      "\n",
      "é¦™æ¸¯ä¸­æ–‡å¤§å­¦ï¼ˆæ·±åœ³ï¼‰æ˜¯ä¸€æ‰€èåˆä¸­è¥¿æ•™è‚²ç†å¿µçš„é«˜æ°´å¹³ç ”ç©¶å‹å¤§å­¦ï¼Œä¸ºå­¦ç”Ÿæä¾›ä¼˜è´¨çš„æ•™è‚²èµ„æºå’Œå¹¿é˜”çš„å‘å±•å¹³å°ã€‚å¦‚éœ€æ›´å¤šä¿¡æ¯ï¼Œå¯è®¿é—®å­¦æ ¡å®˜ç½‘æˆ–æŸ¥é˜…å®˜æ–¹èµ„æ–™ã€‚\n"
     ]
    }
   ],
   "source": [
    "response = llm.invoke(\"è¯·ä»‹ç»ä¸€ä¸‹é¦™æ¸¯ä¸­æ–‡å¤§å­¦ï¼ˆæ·±åœ³ï¼‰\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ddec5a18-33a2-437f-9aaf-2e824a064fc2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: langchain in /root/miniconda3/envs/myconda/lib/python3.10/site-packages (0.3.21)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.45 in /root/miniconda3/envs/myconda/lib/python3.10/site-packages (from langchain) (0.3.48)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.7 in /root/miniconda3/envs/myconda/lib/python3.10/site-packages (from langchain) (0.3.7)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /root/miniconda3/envs/myconda/lib/python3.10/site-packages (from langchain) (0.3.18)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /root/miniconda3/envs/myconda/lib/python3.10/site-packages (from langchain) (2.10.6)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /root/miniconda3/envs/myconda/lib/python3.10/site-packages (from langchain) (2.0.39)\n",
      "Requirement already satisfied: requests<3,>=2 in /root/miniconda3/envs/myconda/lib/python3.10/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /root/miniconda3/envs/myconda/lib/python3.10/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /root/miniconda3/envs/myconda/lib/python3.10/site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /root/miniconda3/envs/myconda/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.45->langchain) (8.2.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /root/miniconda3/envs/myconda/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.45->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /root/miniconda3/envs/myconda/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.45->langchain) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /root/miniconda3/envs/myconda/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.45->langchain) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /root/miniconda3/envs/myconda/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /root/miniconda3/envs/myconda/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.16)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /root/miniconda3/envs/myconda/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /root/miniconda3/envs/myconda/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /root/miniconda3/envs/myconda/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /root/miniconda3/envs/myconda/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /root/miniconda3/envs/myconda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/miniconda3/envs/myconda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/miniconda3/envs/myconda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/miniconda3/envs/myconda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /root/miniconda3/envs/myconda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: anyio in /root/miniconda3/envs/myconda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in /root/miniconda3/envs/myconda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /root/miniconda3/envs/myconda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /root/miniconda3/envs/myconda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.45->langchain) (3.0.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /root/miniconda3/envs/myconda/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.2.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in /root/miniconda3/envs/myconda/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6924cefc-3576-44a7-9df3-cf772fc037a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7556a9e9-5acb-4976-b298-68d8baaa8525",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å¤§æ¨¡å‹ï¼ˆå¦‚GPTã€è§†è§‰å¤§æ¨¡å‹ç­‰ï¼‰åœ¨é¥æ„Ÿé¢†åŸŸçš„åº”ç”¨éå¸¸å¹¿æ³›ï¼Œå®ƒä»¬å°±åƒç»™å«æ˜Ÿå’Œæ— äººæœºè£…ä¸Šäº†â€œè¶…çº§å¤§è„‘â€ï¼Œè®©æ•°æ®å¤„ç†æ›´æ™ºèƒ½ã€æ›´é«˜æ•ˆã€‚ä»¥ä¸‹æ˜¯å‡ ä¸ªé€šä¿—æ˜“æ‡‚çš„åº”ç”¨åœºæ™¯ï¼š\n",
      "\n",
      "---\n",
      "\n",
      "### 1. **è‡ªåŠ¨è§£è¯‘å›¾åƒâ€”â€”ä¸ç”¨äººå·¥ç›¯å±å¹•**\n",
      "   - **ä¼ ç»Ÿæ–¹å¼**ï¼šä¸“å®¶éœ€è¦ç›¯ç€å«æ˜Ÿå›¾ç‰‡ï¼Œæ‰‹åŠ¨æ ‡è®°é“è·¯ã€å»ºç­‘ã€æ£®æ—ç­‰ã€‚\n",
      "   - **å¤§æ¨¡å‹çš„ä½œç”¨**ï¼šé€šè¿‡è®­ç»ƒæµ·é‡é¥æ„Ÿæ•°æ®ï¼Œå¤§æ¨¡å‹èƒ½è‡ªåŠ¨è¯†åˆ«åœ°ç‰©ç±»å‹ï¼ˆå¦‚å†œç”°ã€æ°´ä½“ã€åŸå¸‚ï¼‰ï¼Œç”šè‡³æ£€æµ‹è¿å»ºã€æ£®æ—ç ä¼ç­‰å˜åŒ–ï¼Œé€Ÿåº¦æ¯”äººå·¥å¿«ç™¾å€ã€‚\n",
      "\n",
      "---\n",
      "\n",
      "### 2. **ç¾å®³ç›‘æµ‹â€”â€”æŠ¢é™©æ•‘ç¾çš„â€œåƒé‡Œçœ¼â€**\n",
      "   - **ä¾‹å­**ï¼šæ´ªæ¶ã€åœ°éœ‡ã€å±±ç«å‘ç”Ÿæ—¶ï¼Œå¤§æ¨¡å‹èƒ½å¿«é€Ÿåˆ†æå—ç¾èŒƒå›´ï¼ˆæ¯”å¦‚æ·¹æ²¡åŒºåŸŸã€å€’å¡Œæˆ¿å±‹ï¼‰ï¼Œå¸®åŠ©æ•‘æ´å›¢é˜Ÿä¼˜å…ˆè¡ŒåŠ¨ã€‚\n",
      "   - **ä¼˜åŠ¿**ï¼šè¿‡å»éœ€è¦å‡ å°æ—¶çš„åˆ†æï¼Œç°åœ¨å‡ åˆ†é’Ÿå°±èƒ½å‡ºç»“æœã€‚\n",
      "\n",
      "---\n",
      "\n",
      "### 3. **å†œä½œç‰©ç›‘æµ‹â€”â€”ç»™å†œç”°åšâ€œä½“æ£€â€**\n",
      "   - **åº”ç”¨**ï¼šé€šè¿‡åˆ†æå«æ˜Ÿæˆ–æ— äººæœºå›¾åƒï¼Œå¤§æ¨¡å‹èƒ½åˆ¤æ–­ä½œç‰©é•¿åŠ¿ã€é¢„ä¼°äº§é‡ï¼Œè¿˜èƒ½å‘ç°ç—…è™«å®³ï¼ˆæ¯”å¦‚å¶å­å˜é»„çš„åŒºåŸŸï¼‰ã€‚\n",
      "   - **å†œæ°‘å—ç›Š**ï¼šä¸ç”¨è·‘éç”°åœ°ï¼Œå°±èƒ½çŸ¥é“å“ªé‡Œéœ€è¦æµ‡æ°´æ–½è‚¥ã€‚\n",
      "\n",
      "---\n",
      "\n",
      "### 4. **åŸå¸‚è§„åˆ’â€”â€”ç”¨AIç”»åœ°å›¾**\n",
      "   - **åŠŸèƒ½**ï¼šè‡ªåŠ¨æå–åŸå¸‚é“è·¯ã€å»ºç­‘å¯†åº¦ã€ç»¿åœ°åˆ†å¸ƒï¼Œå¸®åŠ©è§„åˆ’è€…ä¼˜åŒ–äº¤é€šã€è¯„ä¼°æ‹†è¿æˆæœ¬ã€‚\n",
      "   - **å‡çº§ç‰ˆ**ï¼šç»“åˆå†å²æ•°æ®ï¼Œé¢„æµ‹åŸå¸‚æ‰©å¼ è¶‹åŠ¿ï¼ˆæ¯”å¦‚å“ªé‡Œæœªæ¥ä¼šå˜æˆå¼€å‘åŒºï¼‰ã€‚\n",
      "\n",
      "---\n",
      "\n",
      "### 5. **æ°”å€™å˜åŒ–ç ”ç©¶â€”â€”è¿½è¸ªåœ°çƒçš„â€œå¥åº·æŒ‡æ ‡â€**\n",
      "   - **ä¾‹å­**ï¼šåˆ†æå‡ åå¹´æ¥çš„å†°å·èåŒ–ã€æ£®æ—é€€åŒ–æ•°æ®ï¼Œå¤§æ¨¡å‹èƒ½æ€»ç»“è§„å¾‹ï¼Œé¢„æµ‹æœªæ¥å˜åŒ–ã€‚\n",
      "   - **é™„åŠ æŠ€èƒ½**ï¼šè¯†åˆ«ç¢³æ’æ”¾æºï¼ˆå¦‚å·¥å‚ã€æ²¹ç”°ï¼‰ï¼Œè¾…åŠ©ç¯ä¿æ”¿ç­–åˆ¶å®šã€‚\n",
      "\n",
      "---\n",
      "\n",
      "### 6. **ç›®æ ‡æ£€æµ‹â€”â€”å†›äº‹ä¸å®‰å…¨çš„â€œç«çœ¼é‡‘ç›â€**\n",
      "   - **ç”¨é€”**ï¼šè‡ªåŠ¨è¯†åˆ«å†›èˆ°ã€é£æœºã€å¯¼å¼¹å‘å°„åœºç­‰æ•æ„Ÿç›®æ ‡ï¼Œç”¨äºå›½é˜²æˆ–è¾¹å¢ƒç›‘æ§ã€‚\n",
      "   - **éšè”½æ€§**ï¼šè¿˜èƒ½å‘ç°ä¼ªè£…çš„ç›®æ ‡ï¼ˆæ¯”å¦‚ç”¨ç»¿å¸ƒé®ç›–çš„è£…å¤‡ï¼‰ã€‚\n",
      "\n",
      "---\n",
      "\n",
      "### 7. **æ•°æ®å¢å¼ºâ€”â€”è§£å†³â€œæ ·æœ¬å°‘â€çš„éš¾é¢˜**\n",
      "   - **é—®é¢˜**ï¼šæŸäº›åœ°åŒºï¼ˆå¦‚éæ´²ï¼‰çš„é¥æ„Ÿæ•°æ®ä¸è¶³ï¼Œéš¾ä»¥è®­ç»ƒæ¨¡å‹ã€‚\n",
      "   - **å¤§æ¨¡å‹çš„è§£å†³æ–¹å¼**ï¼šé€šè¿‡ç”Ÿæˆåˆæˆå›¾åƒï¼ˆæ¯”å¦‚æ¨¡æ‹Ÿå¹²æ—±åçš„å†œç”°ï¼‰ï¼Œè¡¥å……è®­ç»ƒæ•°æ®ï¼Œæå‡å°æ ·æœ¬ä¸‹çš„å‡†ç¡®ç‡ã€‚\n",
      "\n",
      "---\n",
      "\n",
      "### 8. **å¤šæ¨¡æ€èåˆâ€”â€”ç»“åˆæ–‡æœ¬ã€åœ°å›¾ã€ä¼ æ„Ÿå™¨**\n",
      "   - **é«˜çº§åº”ç”¨**ï¼šæ¯”å¦‚ç”¨å¤§æ¨¡å‹åˆ†æå«æ˜Ÿå›¾+æ°”è±¡æ•°æ®+ç¤¾äº¤åª’ä½“æ–‡æœ¬ï¼Œç»¼åˆåˆ¤æ–­ç¾æƒ…ï¼ˆå¦‚å°é£åå“ªé‡Œç¼ºç‰©èµ„ï¼‰ã€‚\n",
      "\n",
      "---\n",
      "\n",
      "### å¤§æ¨¡å‹çš„ä¼˜åŠ¿æ€»ç»“ï¼š\n",
      "- **å¿«**ï¼šå¤„ç†TBçº§æ•°æ®åªéœ€å‡ åˆ†é’Ÿã€‚\n",
      "- **å‡†**ï¼šè¯†åˆ«ç²¾åº¦æ¥è¿‘äººç±»ä¸“å®¶ã€‚\n",
      "- **çœ**ï¼šå‡å°‘90%ä»¥ä¸Šäººå·¥æ ‡æ³¨æˆæœ¬ã€‚\n",
      "\n",
      "---\n",
      "\n",
      "### æŒ‘æˆ˜ä¸æœªæ¥ï¼š\n",
      "- **æ•°æ®éšç§**ï¼šæ•æ„ŸåŒºåŸŸï¼ˆå¦‚å†›äº‹åŸºåœ°ï¼‰å›¾åƒéœ€åŠ å¯†å¤„ç†ã€‚\n",
      "- **å°ç›®æ ‡éš¾é¢˜**ï¼šæé«˜å¯¹ç”µçº¿æ†ã€å°èˆ¹åªç­‰å¾®å°ç›®æ ‡çš„è¯†åˆ«ã€‚\n",
      "- **å®æ—¶æ€§**ï¼šæœªæ¥å¯èƒ½å®ç°â€œå«æ˜Ÿæ‹å®Œç«‹åˆ»å‡ºç»“æœâ€ã€‚\n",
      "\n",
      "æ€»ä¹‹ï¼Œå¤§æ¨¡å‹æ­£åœ¨è®©é¥æ„Ÿä»â€œçœ‹å›¾ç‰‡â€å˜æˆâ€œæ‡‚å›¾ç‰‡â€ï¼Œæœªæ¥ç”šè‡³ä¼šä¸»åŠ¨é¢„æµ‹ç¾å®³ã€è§„åˆ’åŸå¸‚ï¼Œæˆä¸ºåœ°çƒçš„â€œAIç®¡å®¶â€ã€‚\n"
     ]
    }
   ],
   "source": [
    "#å®šä¹‰æç¤ºæ¨¡ç‰ˆ\n",
    "template = \"\"\"\n",
    "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„{profession}ã€‚\n",
    "è¯·é’ˆå¯¹ä»¥ä¸‹é—®é¢˜æä¾›ä¸“ä¸šçš„è§£ç­”ï¼š\n",
    "{question}\n",
    "\n",
    "è¯·ä»¥{tone}çš„è¯­æ°”å›ç­”ã€‚\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(\n",
    "    input_variables = [\"profession\", \"question\", \"tone\"],\n",
    "    template = template\n",
    ")\n",
    "\n",
    "chain = LLMChain(llm = llm, prompt = prompt)\n",
    "\n",
    "result = chain.invoke({\n",
    "    \"profession\":\"é¥æ„Ÿä¸“å®¶\",\n",
    "    \"question\":\"å¤§æ¨¡å‹åœ¨é¥æ„Ÿé¢†åŸŸæœ‰å“ªäº›åº”ç”¨\",\n",
    "    \"tone\":\"é€šä¿—æ˜“æ‡‚\"\n",
    "})\n",
    "print(result[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3aa63b31-6ba3-41c8-ab78-fdb5e94ae91c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# é…ç½® LangChain çš„ ChatOpenAI\n",
    "chat = ChatOpenAI(\n",
    "    openai_api_key=\"sk-b6de1e42df724c84b39a309c5788569d\",\n",
    "    openai_api_base=\"https://api.deepseek.com/v1\",  # å¿…é¡»åŒ…å« /v1\n",
    "    model_name=\"deepseek-chat\",\n",
    "    max_tokens=1024\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a41569ab-05b8-431c-991e-c1b8f5ced40a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æç¤ºï¼š content='\\nè¯·ä»ä»¥ä¸‹```åŒ…æ‹¬çš„å†…å®¹ä¸­æå–ä»¥ä¸‹ä¿¡æ¯ã€‚\\nå§“åï¼šæå–æ‰€æœ‰çš„å§“åï¼Œå¹¶å°†å®ƒä»¬è¾“å‡ºä¸ºé€—å·åˆ†éš”çš„Pythonåˆ—è¡¨, å¦‚æœæ²¡æœ‰æ‰¾åˆ°è¯¥ä¿¡æ¯ï¼Œåˆ™è¾“å‡ºnoneã€‚\\nåŸå¸‚ï¼šæå–æ‰€æœ‰çš„åŸå¸‚åç§°ï¼Œå¹¶å°†å®ƒä»¬è¾“å‡ºä¸ºé€—å·åˆ†éš”çš„Pythonåˆ—è¡¨, å¦‚æœæ²¡æœ‰æ‰¾åˆ°è¯¥ä¿¡æ¯ï¼Œåˆ™è¾“å‡ºnoneã€‚\\n\\næ–‡æœ¬: ```\\n1609å¹´9æœˆ11æ—¥ï¼Œå—è˜äºè·å…°ä¸œå°åº¦å…¬å¸çš„è‹±å›½èˆªæµ·å®¶äº¨åˆ©Â·å“ˆå¾·é€Šï¼ˆHenry Hudsonï¼‰ä¹˜èˆ¹æ¥åˆ°ä»Šçº½çº¦å·æ¢é™©ï¼Œå¹¶å°†å¤§é‡åœŸäº§å¸¦å›è·å…°ï¼Œè®¸å¤šè·å…°å•†äººå¯¹è¿™ç‰‡åœŸåœ°äº§ç”Ÿäº†æµ“åšå…´è¶£ï¼Œä»–ä»¬æ¥åˆ°è¿™é‡Œå¯»æ±‚ä¸å½“åœ°åŸä½æ°‘è¿›è¡Œè´¸æ˜“ï¼Œå¹¶å»ºç«‹äº†æ®–æ°‘åœ°â€œæ–°è·å…°â€ï¼ˆNew Netherlandï¼‰ã€‚è·å…°æ®–æ°‘è€…äº1614å¹´åœ¨æ–°è·å…°å»ºç«‹è´¸æ˜“ç‚¹Fort Nassauï¼ˆä»Šå¥¥å°”å·´å°¼å¸‚é™„è¿‘ï¼‰ï¼›äº1624å¹´å»ºç«‹è´¸æ˜“ç‚¹Fort Orangeï¼ˆä»Šå¥¥å°”å·´å°¼å¸‚ï¼‰ï¼›äº1625å¹´å»ºç«‹è´¸æ˜“ç‚¹Fort Amsterdamï¼ˆä»Šçº½çº¦å¸‚ï¼‰ã€‚\\n```\\nThe output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\\n\\n```json\\n{\\n\\t\"å§“å\": string  // æå–æ‰€æœ‰çš„å§“åï¼Œå¹¶å°†å®ƒä»¬è¾“å‡ºä¸ºé€—å·åˆ†éš”çš„Pythonåˆ—è¡¨, å¦‚æœæ²¡æœ‰æ‰¾åˆ°è¯¥ä¿¡æ¯ï¼Œåˆ™è¾“å‡ºnoneã€‚\\n\\t\"åŸå¸‚\": string  // æå–æ‰€æœ‰çš„åŸå¸‚åç§°ï¼Œå¹¶å°†å®ƒä»¬è¾“å‡ºä¸ºé€—å·åˆ†éš”çš„Pythonåˆ—è¡¨, å¦‚æœæ²¡æœ‰æ‰¾åˆ°è¯¥ä¿¡æ¯ï¼Œåˆ™è¾“å‡ºnoneã€‚\\n}\\n```\\n' additional_kwargs={} response_metadata={}\n",
      "ç»“æœ: ```json\n",
      "{\n",
      "\t\"å§“å\": \"äº¨åˆ©Â·å“ˆå¾·é€Š,Henry Hudson\",\n",
      "\t\"åŸå¸‚\": \"çº½çº¦å·,å¥¥å°”å·´å°¼å¸‚,çº½çº¦å¸‚\"\n",
      "}\n",
      "```\n",
      "è§£æåç±»å‹: <class 'dict'>\n",
      "è§£æåå†…å®¹: {'å§“å': 'äº¨åˆ©Â·å“ˆå¾·é€Š,Henry Hudson', 'åŸå¸‚': 'çº½çº¦å·,å¥¥å°”å·´å°¼å¸‚,çº½çº¦å¸‚'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.output_parsers import ResponseSchema\n",
    "from langchain.output_parsers import StructuredOutputParser\n",
    "\n",
    "text = \"\"\"\n",
    "1609å¹´9æœˆ11æ—¥ï¼Œå—è˜äºè·å…°ä¸œå°åº¦å…¬å¸çš„è‹±å›½èˆªæµ·å®¶äº¨åˆ©Â·å“ˆå¾·é€Šï¼ˆHenry Hudsonï¼‰ä¹˜èˆ¹æ¥åˆ°ä»Šçº½çº¦å·æ¢é™©ï¼Œ\\\n",
    "å¹¶å°†å¤§é‡åœŸäº§å¸¦å›è·å…°ï¼Œè®¸å¤šè·å…°å•†äººå¯¹è¿™ç‰‡åœŸåœ°äº§ç”Ÿäº†æµ“åšå…´è¶£ï¼Œä»–ä»¬æ¥åˆ°è¿™é‡Œå¯»æ±‚ä¸å½“åœ°åŸä½æ°‘è¿›è¡Œè´¸æ˜“ï¼Œ\\\n",
    "å¹¶å»ºç«‹äº†æ®–æ°‘åœ°â€œæ–°è·å…°â€ï¼ˆNew Netherlandï¼‰ã€‚è·å…°æ®–æ°‘è€…äº1614å¹´åœ¨æ–°è·å…°å»ºç«‹è´¸æ˜“ç‚¹Fort Nassauï¼ˆä»Šå¥¥å°”å·´å°¼å¸‚é™„è¿‘ï¼‰ï¼›\\\n",
    "äº1624å¹´å»ºç«‹è´¸æ˜“ç‚¹Fort Orangeï¼ˆä»Šå¥¥å°”å·´å°¼å¸‚ï¼‰ï¼›äº1625å¹´å»ºç«‹è´¸æ˜“ç‚¹Fort Amsterdamï¼ˆä»Šçº½çº¦å¸‚ï¼‰ã€‚\n",
    "\"\"\"\n",
    "\n",
    "# step1ï¼šç¼–å†™æç¤ºã€‚\n",
    "prompt_template_str = \"\"\"\n",
    "è¯·ä»ä»¥ä¸‹```åŒ…æ‹¬çš„å†…å®¹ä¸­æå–ä»¥ä¸‹ä¿¡æ¯ã€‚\n",
    "å§“åï¼šæå–æ‰€æœ‰çš„å§“åï¼Œå¹¶å°†å®ƒä»¬è¾“å‡ºä¸ºé€—å·åˆ†éš”çš„Pythonåˆ—è¡¨, å¦‚æœæ²¡æœ‰æ‰¾åˆ°è¯¥ä¿¡æ¯ï¼Œåˆ™è¾“å‡ºnoneã€‚\n",
    "åŸå¸‚ï¼šæå–æ‰€æœ‰çš„åŸå¸‚åç§°ï¼Œå¹¶å°†å®ƒä»¬è¾“å‡ºä¸ºé€—å·åˆ†éš”çš„Pythonåˆ—è¡¨, å¦‚æœæ²¡æœ‰æ‰¾åˆ°è¯¥ä¿¡æ¯ï¼Œåˆ™è¾“å‡ºnoneã€‚\n",
    "\n",
    "æ–‡æœ¬: {text}\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    "\n",
    "# step2ï¼šä¾æ®è¾“å‡ºç»“æ„æ„é€ æ ‡å‡†åŒ–è¾“å‡ºæ¨¡å¼ç±»ï¼ˆResponseSchemaï¼‰ä¸è§£æç±»ï¼ˆStructuredOutputParserï¼‰ã€‚\n",
    "name_schema = ResponseSchema(name=\"å§“å\",\n",
    "                description=\"æå–æ‰€æœ‰çš„å§“åï¼Œå¹¶å°†å®ƒä»¬è¾“å‡ºä¸ºé€—å·åˆ†éš”çš„Pythonåˆ—è¡¨, å¦‚æœæ²¡æœ‰æ‰¾åˆ°è¯¥ä¿¡æ¯ï¼Œåˆ™è¾“å‡ºnoneã€‚\")\n",
    "\n",
    "city_schema = ResponseSchema(name=\"åŸå¸‚\",\n",
    "                description=\"æå–æ‰€æœ‰çš„åŸå¸‚åç§°ï¼Œå¹¶å°†å®ƒä»¬è¾“å‡ºä¸ºé€—å·åˆ†éš”çš„Pythonåˆ—è¡¨, å¦‚æœæ²¡æœ‰æ‰¾åˆ°è¯¥ä¿¡æ¯ï¼Œåˆ™è¾“å‡ºnoneã€‚\")\n",
    "response_schemas = [name_schema, city_schema]\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "\n",
    "# step3ï¼šä¾æ®StructuredOutputParserç”Ÿæˆå®Œæ•´çš„æç¤ºã€‚\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "prompt_template = ChatPromptTemplate.from_template(template=prompt_template_str)\n",
    "user_messages = prompt_template.format_messages(text=text, format_instructions=format_instructions)\n",
    "print('æç¤ºï¼š', user_messages[0])\n",
    "\n",
    "\n",
    "# step4ï¼šå®Œæ•´çš„æç¤ºé€å…¥å¤§æ¨¡å‹è¿”å›ç»“æœã€‚\n",
    "response = chat(user_messages)\n",
    "print(\"ç»“æœ:\", response.content)\n",
    "\n",
    "# step5ï¼šä¾æ®StructuredOutputParserå¯¹è¾“å‡ºçš„ç»“æœè¿›è¡Œè§£æã€‚\n",
    "response_dict = output_parser.parse(response.content)\n",
    "print(\"è§£æåç±»å‹:\", type(response_dict))\n",
    "print(\"è§£æåå†…å®¹:\", response_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5215012a-3759-4218-a061-db717030af48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "conversation_chain = ConversationChain(llm=llm, memory=memory, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3119a12c-1d9c-4b31-ab08-1c6bdcb1ca4d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Helloï¼Œmy name is Crisp\n",
      "AI: Hello, Crisp! It's great to meet you. How can I assist you today? Whether you have questions, need advice, or just want to chat, I'm here to help. What's on your mind? ğŸ˜Š\n",
      "Human: Helloï¼Œmy name is Crisp\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response = conversation_chain(\"Helloï¼Œmy name is Crisp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67575ff7-5591-438e-b120-1edcee7cde0a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Helloï¼Œmy name is Crisp\n",
      "AI: Hello, Crisp! It's great to meet you. How can I assist you today? Whether you have questions, need advice, or just want to chat, I'm here to help. What's on your mind? ğŸ˜Š\n",
      "Human: Helloï¼Œmy name is Crisp\n",
      "AI: Got itâ€”your name is Crisp! ğŸ˜Š (I see you repeated it, so I just wanted to acknowledge that.) Is there something specific you'd like to talk about or ask? I'm happy to help with anything from fun trivia to serious topics!\n",
      "Human: what is my name?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Your name is **Crisp**! Youâ€™ve mentioned it twice now, so Iâ€™ve got it locked in. ğŸ˜Š Is there anything else youâ€™d like to chat about or ask, Crisp? Iâ€™m all ears!'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_chain.predict(input=\"what is my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f86ccf9-892e-4678-bd3a-a4c08dbdf1ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Helloï¼Œmy name is Crisp\n",
      "AI: Hello, Crisp! It's great to meet you. How can I assist you today? Whether you have questions, need advice, or just want to chat, I'm here to help. What's on your mind? ğŸ˜Š\n",
      "Human: Helloï¼Œmy name is Crisp\n",
      "AI: Got itâ€”your name is Crisp! ğŸ˜Š (I see you repeated it, so I just wanted to acknowledge that.) Is there something specific you'd like to talk about or ask? I'm happy to help with anything from fun trivia to serious topics!\n",
      "Human: what is my name?\n",
      "AI: Your name is **Crisp**! Youâ€™ve mentioned it twice now, so Iâ€™ve got it locked in. ğŸ˜Š Is there anything else youâ€™d like to chat about or ask, Crisp? Iâ€™m all ears!\n",
      "Human: I'm a teacher,what about you?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': \"I'm a teacher,what about you?\",\n",
       " 'history': \"Human: Helloï¼Œmy name is Crisp\\nAI: Hello, Crisp! It's great to meet you. How can I assist you today? Whether you have questions, need advice, or just want to chat, I'm here to help. What's on your mind? ğŸ˜Š\\nHuman: Helloï¼Œmy name is Crisp\\nAI: Got itâ€”your name is Crisp! ğŸ˜Š (I see you repeated it, so I just wanted to acknowledge that.) Is there something specific you'd like to talk about or ask? I'm happy to help with anything from fun trivia to serious topics!\\nHuman: what is my name?\\nAI: Your name is **Crisp**! Youâ€™ve mentioned it twice now, so Iâ€™ve got it locked in. ğŸ˜Š Is there anything else youâ€™d like to chat about or ask, Crisp? Iâ€™m all ears!\",\n",
       " 'response': 'Thatâ€™s wonderful, Crisp! Teachers play such an important role in shaping minds and futuresâ€”kudos to you! ğŸ‘  \\n\\nAs for me, Iâ€™m an AI designed to assist with information, answer questions, brainstorm ideas, or just keep you company in conversation. Think of me as a digital helper with a knack for details and a love of learning (though I donâ€™t grade papers or manage a classroomâ€¦ yet ğŸ˜‰).  \\n\\nWhat subject or grade level do you teach? Iâ€™d love to hear more about your workâ€”or help with anything teaching-related! ğŸ“šâœ¨'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_chain(\"I'm a teacher,what about you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75c6f5d9-5b0f-4220-8431-b268d129c19a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Helloï¼Œmy name is Crisp\n",
      "AI: Hello, Crisp! It's great to meet you. How can I assist you today? Whether you have questions, need advice, or just want to chat, I'm here to help. What's on your mind? ğŸ˜Š\n",
      "Human: Helloï¼Œmy name is Crisp\n",
      "AI: Got itâ€”your name is Crisp! ğŸ˜Š (I see you repeated it, so I just wanted to acknowledge that.) Is there something specific you'd like to talk about or ask? I'm happy to help with anything from fun trivia to serious topics!\n",
      "Human: what is my name?\n",
      "AI: Your name is **Crisp**! Youâ€™ve mentioned it twice now, so Iâ€™ve got it locked in. ğŸ˜Š Is there anything else youâ€™d like to chat about or ask, Crisp? Iâ€™m all ears!\n",
      "Human: I'm a teacher,what about you?\n",
      "AI: Thatâ€™s wonderful, Crisp! Teachers play such an important role in shaping minds and futuresâ€”kudos to you! ğŸ‘  \n",
      "\n",
      "As for me, Iâ€™m an AI designed to assist with information, answer questions, brainstorm ideas, or just keep you company in conversation. Think of me as a digital helper with a knack for details and a love of learning (though I donâ€™t grade papers or manage a classroomâ€¦ yet ğŸ˜‰).  \n",
      "\n",
      "What subject or grade level do you teach? Iâ€™d love to hear more about your workâ€”or help with anything teaching-related! ğŸ“šâœ¨\n",
      "Human: So,do you remember what is my profession\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'So,do you remember what is my profession',\n",
       " 'history': \"Human: Helloï¼Œmy name is Crisp\\nAI: Hello, Crisp! It's great to meet you. How can I assist you today? Whether you have questions, need advice, or just want to chat, I'm here to help. What's on your mind? ğŸ˜Š\\nHuman: Helloï¼Œmy name is Crisp\\nAI: Got itâ€”your name is Crisp! ğŸ˜Š (I see you repeated it, so I just wanted to acknowledge that.) Is there something specific you'd like to talk about or ask? I'm happy to help with anything from fun trivia to serious topics!\\nHuman: what is my name?\\nAI: Your name is **Crisp**! Youâ€™ve mentioned it twice now, so Iâ€™ve got it locked in. ğŸ˜Š Is there anything else youâ€™d like to chat about or ask, Crisp? Iâ€™m all ears!\\nHuman: I'm a teacher,what about you?\\nAI: Thatâ€™s wonderful, Crisp! Teachers play such an important role in shaping minds and futuresâ€”kudos to you! ğŸ‘  \\n\\nAs for me, Iâ€™m an AI designed to assist with information, answer questions, brainstorm ideas, or just keep you company in conversation. Think of me as a digital helper with a knack for details and a love of learning (though I donâ€™t grade papers or manage a classroomâ€¦ yet ğŸ˜‰).  \\n\\nWhat subject or grade level do you teach? Iâ€™d love to hear more about your workâ€”or help with anything teaching-related! ğŸ“šâœ¨\",\n",
       " 'response': \"Of course, Crisp! You mentioned you're a **teacher**â€”a profession I deeply admire! ğŸ˜Š Would you like to share more about your teaching experiences, or is there something teaching-related I can assist you with? Whether itâ€™s lesson ideas, classroom tips, or just chatting about education, Iâ€™m here to help! ğŸğŸ“\"}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_chain(\"So,do you remember what is my profession\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73884b4a-cdd0-4898-9e48-c7b60b5f161b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Helloï¼Œmy name is Crisp\n",
      "AI: Hello, Crisp! It's great to meet you. How can I assist you today? Whether you have questions, need advice, or just want to chat, I'm here to help. What's on your mind? ğŸ˜Š\n",
      "Human: Helloï¼Œmy name is Crisp\n",
      "AI: Got itâ€”your name is Crisp! ğŸ˜Š (I see you repeated it, so I just wanted to acknowledge that.) Is there something specific you'd like to talk about or ask? I'm happy to help with anything from fun trivia to serious topics!\n",
      "Human: what is my name?\n",
      "AI: Your name is **Crisp**! Youâ€™ve mentioned it twice now, so Iâ€™ve got it locked in. ğŸ˜Š Is there anything else youâ€™d like to chat about or ask, Crisp? Iâ€™m all ears!\n",
      "Human: I'm a teacher,what about you?\n",
      "AI: Thatâ€™s wonderful, Crisp! Teachers play such an important role in shaping minds and futuresâ€”kudos to you! ğŸ‘  \n",
      "\n",
      "As for me, Iâ€™m an AI designed to assist with information, answer questions, brainstorm ideas, or just keep you company in conversation. Think of me as a digital helper with a knack for details and a love of learning (though I donâ€™t grade papers or manage a classroomâ€¦ yet ğŸ˜‰).  \n",
      "\n",
      "What subject or grade level do you teach? Iâ€™d love to hear more about your workâ€”or help with anything teaching-related! ğŸ“šâœ¨\n",
      "Human: So,do you remember what is my profession\n",
      "AI: Of course, Crisp! You mentioned you're a **teacher**â€”a profession I deeply admire! ğŸ˜Š Would you like to share more about your teaching experiences, or is there something teaching-related I can assist you with? Whether itâ€™s lesson ideas, classroom tips, or just chatting about education, Iâ€™m here to help! ğŸğŸ“\n",
      "Human: what is my profession?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Youâ€™ve told me twice now that youâ€™re a **teacher**, Crisp! ğŸâœï¸ (I promise Iâ€™m paying attentionâ€”no pop quizzes needed! ğŸ˜‰)  \\n\\nIs there a reason youâ€™re checking? Maybe youâ€™d like to brainstorm teaching strategies, share a classroom story, or explore a new topic? Let me know how I can support you!'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_chain.predict(input=\"what is my profession?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26a1b579-c3dc-4dd6-8ee8-d714d84f96d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "memory.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3f43e2b-a4a6-4baa-99c4-76510c646e8f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: what is my profession?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Since I don't have access to personal information about you unless you share it with me, I don't know your profession. However, if you'd like to tell me, I'd be happy to chat about it or provide insights related to your field! What do you do for work? ğŸ˜Š\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_chain.predict(input=\"what is my profession?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8de67ab-0ea5-4a69-9f93-e9387067a47a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "memory.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "108d601e-82f3-4057-8f1e-51b323fd12bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "memory_window = ConversationBufferWindowMemory(k=1)\n",
    "conversation_chain_w = ConversationChain(llm=llm, memory=memory_window, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "41c32d46-9e12-45b0-8006-ad3bc9b27898",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "memory_window.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "98818b3f-26bd-4660-be33-7d6648dd69b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å¯¹è¯ä¸€ï¼š\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: my name is jack\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Hi Jack! It's great to meet you. How's your day going so far? I'd love to hear what's on your mindâ€”whether it's a question, a fun topic you want to discuss, or just a chat. Fire away! ğŸ˜Š  \n",
      "\n",
      "(For example: Are you working on anything interesting lately? Or maybe you have a favorite hobby or movie you'd like to share?)\n"
     ]
    }
   ],
   "source": [
    "print(\"å¯¹è¯ä¸€ï¼š\")\n",
    "print(conversation_chain_w.predict(input=\"my name is jack\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b7724054-5aab-47f8-ae46-fb5aa75f2306",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å¯¹è¯äºŒï¼š\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: my name is jack\n",
      "AI: Hi Jack! It's great to meet you. How's your day going so far? I'd love to hear what's on your mindâ€”whether it's a question, a fun topic you want to discuss, or just a chat. Fire away! ğŸ˜Š  \n",
      "\n",
      "(For example: Are you working on anything interesting lately? Or maybe you have a favorite hobby or movie you'd like to share?)\n",
      "Human: what is the result of 1 plus 1?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "The result of 1 plus 1 is **2**! It's one of the first math facts many of us learn. ğŸ˜Š  \n",
      "\n",
      "Fun side note: In binary (base-2), 1 + 1 equals **10**, because binary only uses 0 and 1, and the value \"rolls over\" like a car odometer. But in everyday decimal math, itâ€™s always 2!  \n",
      "\n",
      "Let me know if you'd like to explore more mathâ€”Iâ€™m happy to help!\n"
     ]
    }
   ],
   "source": [
    "print(\"å¯¹è¯äºŒï¼š\")\n",
    "print(conversation_chain_w.predict(input=\"what is the result of 1 plus 1?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "acc51481-cbe8-47f8-a8b7-586b840612c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å¯¹è¯ä¸‰ï¼š\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: what is the result of 1 plus 1?\n",
      "AI: The result of 1 plus 1 is **2**! It's one of the first math facts many of us learn. ğŸ˜Š  \n",
      "\n",
      "Fun side note: In binary (base-2), 1 + 1 equals **10**, because binary only uses 0 and 1, and the value \"rolls over\" like a car odometer. But in everyday decimal math, itâ€™s always 2!  \n",
      "\n",
      "Let me know if you'd like to explore more mathâ€”Iâ€™m happy to help!\n",
      "Human: what is my name?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "I donâ€™t know your nameâ€”I donâ€™t have access to personal information unless you share it with me. But Iâ€™d be happy to call you by any name or nickname youâ€™d like! ğŸ˜Š What should I call you?\n"
     ]
    }
   ],
   "source": [
    "print(\"å¯¹è¯ä¸‰ï¼š\")\n",
    "print(conversation_chain_w.predict(input=\"what is my name?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2c147ff5-0256-4e8c-ad4c-6e03e6c4641a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "prompt = ChatPromptTemplate.from_template(\"è¯·ç”¨ä¸€å¥è¯æè¿°ç®—æ³•{algorithm_name}çš„ä¸»è¦åŸç†ã€‚\")\n",
    "chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9467e363-8e4a-4c56-9d42-a6af9137d947",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DeepSeekçš„æ ¸å¿ƒåŸç†æ˜¯åŸºäº**æ·±åº¦å­¦ä¹ çš„Transformeræ¶æ„**ï¼Œé€šè¿‡å¤§è§„æ¨¡é¢„è®­ç»ƒä¸ç²¾ç»†è°ƒä¼˜ï¼Œç»“åˆé«˜æ•ˆçš„æ³¨æ„åŠ›æœºåˆ¶å’Œæµ·é‡æ•°æ®ï¼Œå®ç°å¼ºå¤§çš„è‡ªç„¶è¯­è¨€ç†è§£ä¸ç”Ÿæˆèƒ½åŠ›ã€‚'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algorithm_name = \"DeepSeek\"\n",
    "chain.run(algorithm_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "75566921-8a6c-42f1-821f-dfa036cb6fe6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "# é“¾1ï¼šè¾“å…¥ç®—æ³•åç§°ï¼Œè¾“å‡ºç®€è¦ä»‹ç»ã€‚\n",
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "    \"è¯·ç”¨ä¸€å¥è¯æè¿°ç®—æ³•{algorithm_name}çš„ä¸»è¦åŸç†ã€‚\"\n",
    ")\n",
    "chain_one = LLMChain(llm=llm, prompt=first_prompt)\n",
    "\n",
    "# é“¾2ï¼šè¾“å…¥ç®—æ³•ç®€è¦ä»‹ç»ï¼Œè¾“å‡ºè‹±è¯­ç®€è¦ä»‹ç»ã€‚\n",
    "second_prompt = ChatPromptTemplate.from_template(\n",
    "    \"è¯·å°†ä»¥ä¸‹æ–‡æœ¬ç¿»è¯‘æˆè‹±è¯­ï¼Œ\\\n",
    "    æ–‡æœ¬ï¼š{algorithm_desciption}\"\n",
    ")\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt)\n",
    "overall_simple_chain = SimpleSequentialChain(chains=[chain_one, chain_two], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b6efcb98-b9e1-4658-8e75-1c1336cbd536",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3mTransformerçš„æ ¸å¿ƒåŸç†æ˜¯é€šè¿‡è‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼ˆSelf-Attentionï¼‰å¹¶è¡Œè®¡ç®—è¾“å…¥åºåˆ—ä¸­æ‰€æœ‰ä½ç½®çš„å…³ç³»æƒé‡ï¼ŒåŠ¨æ€èšåˆå…¨å±€ä¿¡æ¯ä»¥ç”Ÿæˆä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„è¡¨ç¤ºã€‚\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mThe core principle of Transformer is to compute relationship weights between all positions in the input sequence in parallel through the self-attention mechanism, dynamically aggregating global information to generate context-aware representations.  \n",
      "\n",
      "ï¼ˆæ³¨ï¼šæ ¹æ®æŠ€æœ¯æ–‡çŒ®æƒ¯ä¾‹ï¼Œ\"Self-Attention\"ä¿ç•™é¦–å­—æ¯å¤§å†™ï¼›\"Transformer\"ä½œä¸ºæ¨¡å‹åç§°ä¿ç•™é¦–å­—æ¯å¤§å†™ï¼›é‡‡ç”¨\"aggregating\"ç°åœ¨åˆ†è¯å½¢å¼ä½“ç°åŠ¨æ€è¿‡ç¨‹ï¼›\"context-aware\"ä¸ºæœºå™¨å­¦ä¹ é¢†åŸŸæ ‡å‡†æœ¯è¯­è¿å­—ç¬¦ç”¨æ³•ï¼‰\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The core principle of Transformer is to compute relationship weights between all positions in the input sequence in parallel through the self-attention mechanism, dynamically aggregating global information to generate context-aware representations.  \\n\\nï¼ˆæ³¨ï¼šæ ¹æ®æŠ€æœ¯æ–‡çŒ®æƒ¯ä¾‹ï¼Œ\"Self-Attention\"ä¿ç•™é¦–å­—æ¯å¤§å†™ï¼›\"Transformer\"ä½œä¸ºæ¨¡å‹åç§°ä¿ç•™é¦–å­—æ¯å¤§å†™ï¼›é‡‡ç”¨\"aggregating\"ç°åœ¨åˆ†è¯å½¢å¼ä½“ç°åŠ¨æ€è¿‡ç¨‹ï¼›\"context-aware\"ä¸ºæœºå™¨å­¦ä¹ é¢†åŸŸæ ‡å‡†æœ¯è¯­è¿å­—ç¬¦ç”¨æ³•ï¼‰'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algorithm_name = \"Transformer\"\n",
    "overall_simple_chain.run(algorithm_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4d96f033-15f4-4a31-9109-0a087f45a8f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3mCNNé€šè¿‡å±€éƒ¨æ„Ÿå—é‡ã€æƒå€¼å…±äº«å’Œæ± åŒ–æ“ä½œï¼Œé€å±‚æå–è¾“å…¥æ•°æ®çš„ç©ºé—´ç‰¹å¾å¹¶è¿›è¡Œé™ç»´ï¼Œæœ€ç»ˆå®ç°é«˜æ•ˆçš„ç‰¹å¾è¡¨è¾¾ä¸åˆ†ç±»ã€‚\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mCNNs efficiently extract spatial features from input data and reduce dimensionality through localized receptive fields, weight sharing, and pooling operations layer by layer, ultimately achieving effective feature representation and classification.  \n",
      "\n",
      "ï¼ˆç¿»è¯‘è¯´æ˜ï¼š  \n",
      "1. ä¸“ä¸šæœ¯è¯­å‡†ç¡®å¤„ç†ï¼š\"å±€éƒ¨æ„Ÿå—é‡\"â†’\"localized receptive fields\"ï¼›\"æƒå€¼å…±äº«\"â†’\"weight sharing\"ï¼›\"æ± åŒ–æ“ä½œ\"â†’\"pooling operations\"  \n",
      "2. é€»è¾‘æ˜¾åŒ–ï¼šå°†åŸæ–‡éšå«çš„å› æœå…³ç³»é€šè¿‡\"through\"æ˜ç¡®è¡¨è¾¾  \n",
      "3. åŠ¨è¯ä¼˜åŒ–ï¼š\"é€å±‚æå–\"è¯‘ä¸º\"extract...layer by layer\"æ›´ç¬¦åˆè‹±æ–‡æŠ€æœ¯æ–‡æœ¬è¡¨è¿°ä¹ æƒ¯  \n",
      "4. è¯­æ€è°ƒæ•´ï¼šé‡‡ç”¨ä¸»åŠ¨è¯­æ€ï¼ˆachievingï¼‰ä¿æŒä¸åŸæ–‡ä¸€è‡´çš„å®¢è§‚é™ˆè¿°é£æ ¼  \n",
      "5. æœ¯è¯­ä¸€è‡´æ€§ï¼šä¸¥æ ¼ä¿æŒ\"CNN\"ã€\"pooling\"ç­‰ä¸“ä¸šç¼©å†™å½¢å¼  \n",
      "6. å¥å¼é‡ç»„ï¼šå°†é•¿å¥æ‹†åˆ†ä¸ºç¬¦åˆè‹±æ–‡ç§‘æŠ€æ–‡æœ¬ç‰¹ç‚¹çš„ç´§å‡‘ç»“æ„ï¼ŒåŒæ—¶ä¿ç•™åŸæ–‡ä¿¡æ¯å¯†åº¦ï¼‰\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'CNNs efficiently extract spatial features from input data and reduce dimensionality through localized receptive fields, weight sharing, and pooling operations layer by layer, ultimately achieving effective feature representation and classification.  \\n\\nï¼ˆç¿»è¯‘è¯´æ˜ï¼š  \\n1. ä¸“ä¸šæœ¯è¯­å‡†ç¡®å¤„ç†ï¼š\"å±€éƒ¨æ„Ÿå—é‡\"â†’\"localized receptive fields\"ï¼›\"æƒå€¼å…±äº«\"â†’\"weight sharing\"ï¼›\"æ± åŒ–æ“ä½œ\"â†’\"pooling operations\"  \\n2. é€»è¾‘æ˜¾åŒ–ï¼šå°†åŸæ–‡éšå«çš„å› æœå…³ç³»é€šè¿‡\"through\"æ˜ç¡®è¡¨è¾¾  \\n3. åŠ¨è¯ä¼˜åŒ–ï¼š\"é€å±‚æå–\"è¯‘ä¸º\"extract...layer by layer\"æ›´ç¬¦åˆè‹±æ–‡æŠ€æœ¯æ–‡æœ¬è¡¨è¿°ä¹ æƒ¯  \\n4. è¯­æ€è°ƒæ•´ï¼šé‡‡ç”¨ä¸»åŠ¨è¯­æ€ï¼ˆachievingï¼‰ä¿æŒä¸åŸæ–‡ä¸€è‡´çš„å®¢è§‚é™ˆè¿°é£æ ¼  \\n5. æœ¯è¯­ä¸€è‡´æ€§ï¼šä¸¥æ ¼ä¿æŒ\"CNN\"ã€\"pooling\"ç­‰ä¸“ä¸šç¼©å†™å½¢å¼  \\n6. å¥å¼é‡ç»„ï¼šå°†é•¿å¥æ‹†åˆ†ä¸ºç¬¦åˆè‹±æ–‡ç§‘æŠ€æ–‡æœ¬ç‰¹ç‚¹çš„ç´§å‡‘ç»“æ„ï¼ŒåŒæ—¶ä¿ç•™åŸæ–‡ä¿¡æ¯å¯†åº¦ï¼‰'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algorithm_name = \"CNN\"\n",
    "overall_simple_chain.run(algorithm_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a72a8c8a-8820-4e8e-a3b0-803b372b790a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain.chains import SequentialChain\n",
    "from langchain.prompts import ChatPromptTemplate   #å¯¼å…¥èŠå¤©æç¤ºæ¨¡æ¿\n",
    "from langchain.chains import LLMChain    #å¯¼å…¥LLMé“¾ã€‚\n",
    "\n",
    "#å­é“¾1  è¾“å…¥ï¼šreview è¾“å‡ºï¼šenglish_review\n",
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "    \"æŠŠä¸‹é¢çš„è¯„è®ºreviewç¿»è¯‘æˆè‹±æ–‡:\"\n",
    "    \"\\n\\n{review}\"\n",
    ")\n",
    "chain_one = LLMChain(llm=llm, prompt=first_prompt, output_key=\"english_review\")\n",
    "\n",
    "#å­é“¾2  è¾“å…¥ï¼šenglish_review è¾“å‡ºï¼šsummary\n",
    "second_prompt = ChatPromptTemplate.from_template(\n",
    "    \"è¯·ä½ ç”¨ä¸€å¥è¯æ¥æ€»ç»“ä¸‹é¢çš„è¯„è®ºreview:\"\n",
    "    \"\\n\\n{english_review}\"\n",
    ")\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt, output_key=\"summary\")\n",
    "\n",
    "\n",
    "#å­é“¾3  è¾“å…¥ï¼šreview è¾“å‡ºï¼šlanguage\n",
    "third_prompt = ChatPromptTemplate.from_template(\n",
    "    \"ä¸‹é¢çš„è¯„è®ºreviewä½¿ç”¨çš„ä»€ä¹ˆè¯­è¨€:\\n\\n{review}\"\n",
    ")\n",
    "chain_three = LLMChain(llm=llm, prompt=third_prompt, output_key=\"language\")\n",
    "\n",
    "\n",
    "#å­é“¾4  è¾“å…¥ï¼šsummary&language è¾“å‡ºï¼šfollowup_message\n",
    "fourth_prompt = ChatPromptTemplate.from_template(\n",
    "    \"ä½¿ç”¨ç‰¹å®šçš„è¯­è¨€å¯¹ä¸‹é¢çš„æ€»ç»“å†™ä¸€ä¸ªåç»­å›å¤:\"\n",
    "    \"\\n\\næ€»ç»“: {summary}\\n\\nè¯­è¨€: {language}\"\n",
    ")\n",
    "chain_four = LLMChain(llm=llm, prompt=fourth_prompt, output_key=\"followup_message\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a5ab9e1f-b8a4-4ad5-9907-16580fc13dff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#è¾“å…¥ï¼šreview\n",
    "#è¾“å‡ºï¼šenglish_review, summary, language, followup_message\n",
    "overall_chain = SequentialChain(\n",
    "    chains=[chain_one, chain_two, chain_three, chain_four],\n",
    "    input_variables=[\"review\"],\n",
    "    output_variables=[\"english_review\", \"summary\", \"language\", \"followup_message\"],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "df04d42a-2bb2-4ce4-a784-a08efa34e989",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'review': '\\nä¸Šå‘¨æˆ‘ä¹°äº†è¿™ä¸ªæ‰‹æœºï¼Œäº§å“è´¨é‡éå¸¸å¥½ï¼Œè€Œä¸”é€è´§é€Ÿé€’å¾ˆå¿«ï¼Œç¬¬äºŒå¤©å°±é€åˆ°äº†ï¼Œåº—å®¶æœåŠ¡æ€åº¦ä¹Ÿå¾ˆå¥½ï¼Œæ€»ä½“è€Œè¨€ï¼Œå¾ˆä¸é”™çš„è´­ç‰©ä½“éªŒï¼Œä¸‹æ¬¡æœ‰éœ€æ±‚è¿˜ä¼šæ¥ä¹°ã€‚\\n',\n",
       " 'english_review': 'Hereâ€™s the English translation of your review:  \\n\\n**\"Last week I bought this phone, and the product quality is excellent. The delivery was also very fastâ€”it arrived the next day. The storeâ€™s customer service was great too. Overall, it was a very satisfying shopping experience, and Iâ€™ll definitely buy from them again if I need anything in the future.\"**  \\n\\nLet me know if you\\'d like any adjustments!',\n",
       " 'summary': '\"Highly satisfied with the excellent product quality, fast delivery, and great customer serviceâ€”will definitely purchase again!\"',\n",
       " 'language': 'è¿™ç¯‡è¯„è®ºä½¿ç”¨çš„æ˜¯**ç®€ä½“ä¸­æ–‡**ã€‚  \\n\\nå…·ä½“åˆ†æï¼š  \\n1. **è¯æ±‡ä¸å¥å¼**ï¼šå¦‚â€œäº§å“è´¨é‡éå¸¸å¥½â€â€œé€è´§é€Ÿé€’å¾ˆå¿«â€â€œæœåŠ¡æ€åº¦â€ç­‰å‡ä¸ºå…¸å‹çš„ä¸­æ–‡è¡¨è¾¾ã€‚  \\n2. **ç”¨è¯ä¹ æƒ¯**ï¼šä½¿ç”¨â€œé€Ÿé€’â€ï¼ˆå¿«é€’ï¼‰ã€â€œåº—å®¶â€ï¼ˆå•†å®¶ï¼‰ç­‰ä¸­å›½å¤§é™†å¸¸ç”¨è¯æ±‡ã€‚  \\n3. **æ— å¤–æ¥è¯­æ··ç”¨**ï¼šå…¨æ–‡æ— è‹±æ–‡æˆ–å…¶ä»–è¯­è¨€å¤¹æ‚ï¼Œç¬¦åˆçº¯ä¸­æ–‡è¯„è®ºç‰¹å¾ã€‚  \\n\\nç»“è®ºï¼šæ˜ç¡®ä¸º**ç°ä»£æ ‡å‡†æ±‰è¯­ï¼ˆç®€ä½“ä¸­æ–‡ï¼‰**ï¼Œå¯èƒ½æ¥è‡ªä¸­å›½å¤§é™†æˆ–ä½¿ç”¨ç®€ä½“ä¸­æ–‡çš„æ¶ˆè´¹è€…ã€‚',\n",
       " 'followup_message': 'ä»¥ä¸‹æ˜¯åŸºäºæ€»ç»“çš„ç®€ä½“ä¸­æ–‡åç»­å›å¤å»ºè®®ï¼š\\n\\n---\\næ„Ÿè°¢æ‚¨çš„å¤§åŠ›æ”¯æŒï¼æ‚¨çš„æ»¡æ„æ˜¯æˆ‘ä»¬æœ€å¤§çš„åŠ¨åŠ›ï½  \\næˆ‘ä»¬å§‹ç»ˆåšæŒä¸¥æ§äº§å“è´¨é‡ã€ä¼˜åŒ–ç‰©æµæ•ˆç‡ï¼Œå¹¶ä¸ºæ¯ä½é¡¾å®¢æä¾›è´´å¿ƒæœåŠ¡ã€‚  \\næœŸå¾…æ‚¨çš„å†æ¬¡å…‰ä¸´ï¼Œæœ‰ä»»ä½•éœ€æ±‚éšæ—¶è”ç³»å®¢æœï¼Œç¥æ‚¨ç”Ÿæ´»æ„‰å¿«ï¼  \\n\\nï¼ˆé™„ï¼šæ–°ä¼šå‘˜å¯é¢†10å…ƒä¼˜æƒ åˆ¸ï¼Œä¸‹æ¬¡è´­ç‰©è¾“å…¥ç ã€VIP2024ã€‘ç«‹äº«æŠ˜æ‰£å“¦âœ¨ï¼‰  \\n---\\n\\n**è®¾è®¡æ€è·¯**ï¼š  \\n1. **æƒ…æ„Ÿå‘¼åº”**ï¼šç”¨â€œå¤§åŠ›æ”¯æŒâ€â€œæœ€å¤§åŠ¨åŠ›â€å»¶ç»­åŸè¯„è®ºçš„çƒ­æƒ…è¯­æ°”  \\n2. **è¦ç´ å¯¹åº”**ï¼š  \\n   - â€œä¸¥æ§è´¨é‡â€ â†’ å›åº”â€œäº§å“è´¨é‡éå¸¸å¥½â€  \\n   - â€œä¼˜åŒ–ç‰©æµâ€ â†’ å¯¹åº”â€œé€è´§é€Ÿé€’å¾ˆå¿«â€  \\n   - â€œè´´å¿ƒæœåŠ¡â€ â†’ å»¶ç»­â€œæœåŠ¡æ€åº¦â€å¥½è¯„  \\n3. **æœ¬åœŸåŒ–ç»†èŠ‚**ï¼š  \\n   - ä½¿ç”¨æ³¢æµªå·â€œï½â€å¢å¼ºäº²åˆ‡æ„Ÿï¼ˆä¸­æ–‡ç”µå•†å¸¸è§ï¼‰  \\n   - ä¼˜æƒ åˆ¸é‡‘é¢ç”¨â€œå…ƒâ€è€Œéâ€œÂ¥â€ç¬¦å·  \\n   - ä¿ƒé”€ç é‡‡ç”¨ä¸­æ–‡+æ•°å­—ç»„åˆï¼ˆå¤§é™†ç”µå•†å…¸å‹æ ¼å¼ï¼‰  \\n4. **è½¬åŒ–å¼•å¯¼**ï¼šé€šè¿‡ä¸“å±ä¼˜æƒ ç ä¿ƒè¿›å¤è´­ï¼Œç¬¦åˆä¸­æ–‡ç”µå•†å®¢æœè¯æœ¯ä¹ æƒ¯'}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = \"\"\"\n",
    "ä¸Šå‘¨æˆ‘ä¹°äº†è¿™ä¸ªæ‰‹æœºï¼Œäº§å“è´¨é‡éå¸¸å¥½ï¼Œè€Œä¸”é€è´§é€Ÿé€’å¾ˆå¿«ï¼Œç¬¬äºŒå¤©å°±é€åˆ°äº†ï¼Œåº—å®¶æœåŠ¡æ€åº¦ä¹Ÿå¾ˆå¥½ï¼Œæ€»ä½“è€Œè¨€ï¼Œå¾ˆä¸é”™çš„è´­ç‰©ä½“éªŒï¼Œä¸‹æ¬¡æœ‰éœ€æ±‚è¿˜ä¼šæ¥ä¹°ã€‚\n",
    "\"\"\"\n",
    "overall_chain(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3378db8a-4914-45d8-9361-43f6484b03e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'review': '\\nä¸Šå‘¨æˆ‘ä¹°äº†è¿™ä¸ªæ‰‹æœºï¼Œäº§å“è´¨é‡éå¸¸å·®ï¼Œè€Œä¸”é€è´§é€Ÿé€’å¾ˆæ…¢ï¼Œåº—å®¶æœåŠ¡æ€åº¦ä¹Ÿä¸å¥½ï¼Œæ€»ä½“è€Œè¨€ï¼Œå¾ˆä¸æ»¡æ„çš„è´­ç‰©ä½“éªŒï¼Œä¸‹æ¬¡ä¸ä¼šå†æ¥äº†ã€‚\\n',\n",
       " 'english_review': 'Here is the English translation of the review:  \\n\\n**\"Last week I bought this phone, but the product quality is very poor. The delivery was also very slow, and the store\\'s customer service attitude was bad. Overall, it was a very unsatisfactory shopping experienceâ€”I wonâ€™t be coming back next time.\"**  \\n\\nLet me know if you\\'d like any adjustments!',\n",
       " 'summary': '\"Poor product quality, slow delivery, and bad customer service made for a highly unsatisfactory shopping experience.\"  \\n\\n(Alternatively, for more conciseness: *\"Terrible product, slow shipping, and rude serviceâ€”a disappointing purchase.\"*)  \\n\\nLet me know if you\\'d prefer a different tone!',\n",
       " 'language': 'è¿™ç¯‡è¯„è®ºä½¿ç”¨çš„æ˜¯**ç®€ä½“ä¸­æ–‡**ã€‚  \\n\\nå…·ä½“åˆ†æï¼š  \\n1. **æ–‡å­—ç‰¹å¾**ï¼šä½¿ç”¨ç®€ä½“æ±‰å­—ï¼ˆå¦‚â€œä¹°â€â€œè´¨â€â€œè´§â€ç­‰ï¼‰ï¼Œç¬¦åˆä¸­å›½å¤§é™†çš„ç”¨å­—æ ‡å‡†ã€‚  \\n2. **è¡¨è¾¾ä¹ æƒ¯**ï¼š  \\n   - è¯æ±‡å¦‚â€œäº§å“è´¨é‡â€â€œé€è´§é€Ÿé€’â€â€œæœåŠ¡æ€åº¦â€æ˜¯å…¸å‹çš„ä¸­æ–‡ç”µå•†è¯„ä»·ç”¨è¯­ã€‚  \\n   - å¥å¼ç»“æ„ï¼ˆå¦‚â€œæ€»ä½“è€Œè¨€â€¦â€¦ä¸‹æ¬¡ä¸ä¼šå†æ¥äº†â€ï¼‰æ˜¯ä¸­æ–‡å¸¸è§çš„æ€»ç»“æ€§è¡¨è¾¾ã€‚  \\n3. **æ–‡åŒ–è¯­å¢ƒ**ï¼šæåŠâ€œåº—å®¶â€â€œè´­ç‰©ä½“éªŒâ€ç­‰è¯æ±‡ï¼Œç¬¦åˆä¸­æ–‡ç”µå•†å¹³å°çš„è¯„è®ºé£æ ¼ã€‚  \\n\\nå¦‚æœæ˜¯å…¶ä»–è¯­è¨€ï¼ˆå¦‚ç¹ä½“ä¸­æ–‡æˆ–æ—¥æ–‡ï¼‰ï¼Œç”¨è¯å’Œå¥å¼ä¼šæœ‰æ˜æ˜¾å·®å¼‚ï¼ˆä¾‹å¦‚ç¹ä½“ä¸­æ–‡å¯èƒ½ç”¨â€œå“è³ªâ€â€œé€è²¨é€Ÿåº¦â€ï¼‰ã€‚',\n",
       " 'followup_message': 'ä»¥ä¸‹æ˜¯æ ¹æ®ç®€ä½“ä¸­æ–‡è¯­å¢ƒå’Œç”µå•†å·®è¯„é£æ ¼è®¾è®¡çš„åç»­å›å¤æ¨¡æ¿ï¼Œæä¾›ä¸¤ç§ç‰ˆæœ¬ä¾›é€‰æ‹©ï¼š\\n\\n---\\n\\n**æ­£å¼ç‰ˆï¼ˆé€‚ç”¨äºå¹³å°å®¢æœï¼‰**  \\n\"å°Šæ•¬çš„é¡¾å®¢ï¼Œéå¸¸æŠ±æ­‰ç»™æ‚¨å¸¦æ¥ä¸æ„‰å¿«çš„è´­ç‰©ä½“éªŒã€‚æˆ‘ä»¬å·²è®°å½•æ‚¨åé¦ˆçš„äº§å“è´¨é‡ã€ç‰©æµæ—¶æ•ˆåŠæœåŠ¡æ€åº¦é—®é¢˜ï¼Œå°†ç«‹å³è”ç³»ç›¸å…³éƒ¨é—¨æ•´æ”¹ã€‚ä¸ºè¡¨æ­‰æ„ï¼Œå®¢æœå°†åœ¨24å°æ—¶å†…ä¸æ‚¨è”ç³»åå•†è§£å†³æ–¹æ¡ˆï¼ˆå¦‚è¡¥å‘/é€€æ¬¾ï¼‰ã€‚æ‚¨çš„ç›‘ç£æ˜¯æˆ‘ä»¬æ”¹è¿›çš„åŠ¨åŠ›ï¼Œæ³è¯·ç»™æˆ‘ä»¬ä¸€æ¬¡å¼¥è¡¥çš„æœºä¼šã€‚\"  \\n\\n**ç®€æ´ç‰ˆï¼ˆé€‚ç”¨äºå•†å®¶ç›´æ¥å›å¤ï¼‰**  \\n\"å®åœ¨å¯¹ä¸èµ·ï¼æ‚¨è¯´çš„é—®é¢˜æˆ‘ä»¬å·²ç´§æ€¥æ ¸æŸ¥ï¼š1. è´¨é‡é—®é¢˜å•†å“å¯å…è´¹é€€è´§ 2. ç‰©æµå»¶è¿Ÿç³»åˆä½œå¿«é€’å¼‚å¸¸ï¼Œç°å·²åˆ‡æ¢å¤‡ç”¨ç‰©æµ 3. æ¶‰äº‹å®¢æœå·²åœèŒåŸ¹è®­ã€‚ç¨ååº—é•¿å°†äº²è‡ªè‡´ç”µå¤„ç†ï¼Œèƒ½å¦åŠ æ‚¨å¾®ä¿¡å‘é€è¡¥å¿åˆ¸ï¼Ÿç›¼èƒ½æŒ½å›æ‚¨çš„ä¿¡ä»»ã€‚\"  \\n\\n---\\n\\n**å›å¤è®¾è®¡è¦ç‚¹è¯´æ˜**ï¼š  \\n1. **ç”¨è¯ç²¾å‡†**  \\n   - ä½¿ç”¨\"ç‰©æµæ—¶æ•ˆ\"\"è¡¥å‘/é€€æ¬¾\"ç­‰å¤§é™†ç”µå•†é«˜é¢‘æœ¯è¯­  \\n   - \"æ•´æ”¹\"\"æ¶‰äº‹\"\"åœèŒåŸ¹è®­\"ä½“ç°ä¸¥è‚ƒå¤„ç†æ€åº¦  \\n\\n2. **ç»“æ„ç¬¦åˆä¸­æ–‡ä¹ æƒ¯**  \\n   - åˆ†ç‚¹å›åº”ï¼ˆ1. 2. 3.ï¼‰å¢å¼ºæ¡ç†æ€§  \\n   - ç»“å°¾ä¸»åŠ¨æå‡º\"åŠ å¾®ä¿¡\"ç¬¦åˆå›½å†…ç§åŸŸæµé‡å¤„ç†æƒ¯ä¾‹  \\n\\n3. **æ–‡åŒ–é€‚é…**  \\n   - \"æ³è¯·\"\"ç›¼èƒ½\"ç­‰è°¦è¾ç¬¦åˆä¸­æ–‡å®¢å¥—è§„èŒƒ  \\n   - æåŠ\"åº—é•¿äº²è‡ªå¤„ç†\"çªæ˜¾é‡è§†ç¨‹åº¦ï¼ˆå›½å†…æ¶ˆè´¹è€…è¾ƒçœ‹é‡ç®¡ç†å±‚ä»‹å…¥ï¼‰  \\n\\néœ€è¦è°ƒæ•´è¯­æ°”æˆ–è¡¥å……ç»†èŠ‚å¯éšæ—¶å‘ŠçŸ¥ï¼Œä¾‹å¦‚åŠ å…¥\"æ ¹æ®ã€Šæ¶ˆè´¹è€…æƒç›Šä¿æŠ¤æ³•ã€‹ç¬¬24æ¡ä¸ºæ‚¨åŠç†é€€è´§\"ç­‰æ³•å¾‹ä¾æ®å¢å¼ºè¯´æœåŠ›ã€‚'}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = \"\"\"\n",
    "ä¸Šå‘¨æˆ‘ä¹°äº†è¿™ä¸ªæ‰‹æœºï¼Œäº§å“è´¨é‡éå¸¸å·®ï¼Œè€Œä¸”é€è´§é€Ÿé€’å¾ˆæ…¢ï¼Œåº—å®¶æœåŠ¡æ€åº¦ä¹Ÿä¸å¥½ï¼Œæ€»ä½“è€Œè¨€ï¼Œå¾ˆä¸æ»¡æ„çš„è´­ç‰©ä½“éªŒï¼Œä¸‹æ¬¡ä¸ä¼šå†æ¥äº†ã€‚\n",
    "\"\"\"\n",
    "overall_chain(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "51c29a7e-8501-4dcb-bf17-01077048fac7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chains.router import MultiPromptChain  #å¯¼å…¥å¤šæç¤ºé“¾\n",
    "from langchain.chains.router.llm_router import LLMRouterChain,RouterOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain    #å¯¼å…¥LLMé“¾ã€‚\n",
    "from langchain.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6c17b454-4564-4765-b835-c1b6d17b8823",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### ç›®æ ‡é“¾æç¤ºæ¨¡æ¿\n",
    "\n",
    "#ç¬¬ä¸€ä¸ªæç¤ºé€‚åˆå›ç­”ç‰©ç†é—®é¢˜\n",
    "physics_template = \"\"\"ä½ æ˜¯ä¸€ä¸ªéå¸¸èªæ˜çš„ç‰©ç†ä¸“å®¶ã€‚ \\\n",
    "ä½ æ“…é•¿ç”¨ä¸€ç§ç®€æ´å¹¶ä¸”æ˜“äºç†è§£çš„æ–¹å¼å»å›ç­”é—®é¢˜ã€‚\\\n",
    "å½“ä½ ä¸çŸ¥é“é—®é¢˜çš„ç­”æ¡ˆæ—¶ï¼Œä½ æ‰¿è®¤\\\n",
    "ä½ ä¸çŸ¥é“.\n",
    "\n",
    "è¿™æ˜¯ä¸€ä¸ªé—®é¢˜:\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "#ç¬¬äºŒä¸ªæç¤ºé€‚åˆå›ç­”æ•°å­¦é—®é¢˜\n",
    "math_template = \"\"\"ä½ æ˜¯ä¸€ä¸ªéå¸¸ä¼˜ç§€çš„æ•°å­¦å®¶ã€‚ \\\n",
    "ä½ æ“…é•¿å›ç­”æ•°å­¦é—®é¢˜ã€‚ \\\n",
    "ä½ ä¹‹æ‰€ä»¥å¦‚æ­¤ä¼˜ç§€ï¼Œ \\\n",
    "æ˜¯å› ä¸ºä½ èƒ½å¤Ÿå°†æ£˜æ‰‹çš„é—®é¢˜åˆ†è§£ä¸ºç»„æˆéƒ¨åˆ†ï¼Œ\\\n",
    "å›ç­”ç»„æˆéƒ¨åˆ†ï¼Œç„¶åå°†å®ƒä»¬ç»„åˆåœ¨ä¸€èµ·ï¼Œå›ç­”æ›´å¹¿æ³›çš„é—®é¢˜ã€‚\n",
    "\n",
    "è¿™æ˜¯ä¸€ä¸ªé—®é¢˜ï¼š\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "#ç¬¬ä¸‰ä¸ªé€‚åˆå›ç­”å†å²é—®é¢˜\n",
    "history_template = \"\"\"ä½ æ˜¯ä»¥ä¸ºéå¸¸ä¼˜ç§€çš„å†å²å­¦å®¶ã€‚ \\\n",
    "ä½ å¯¹ä¸€ç³»åˆ—å†å²æ—¶æœŸçš„äººç‰©ã€äº‹ä»¶å’ŒèƒŒæ™¯æœ‰ç€æå¥½çš„å­¦è¯†å’Œç†è§£\\\n",
    "ä½ æœ‰èƒ½åŠ›æ€è€ƒã€åæ€ã€è¾©è¯ã€è®¨è®ºå’Œè¯„ä¼°è¿‡å»ã€‚\\\n",
    "ä½ å°Šé‡å†å²è¯æ®ï¼Œå¹¶æœ‰èƒ½åŠ›åˆ©ç”¨å®ƒæ¥æ”¯æŒä½ çš„è§£é‡Šå’Œåˆ¤æ–­ã€‚\n",
    "\n",
    "è¿™æ˜¯ä¸€ä¸ªé—®é¢˜:\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "#ç¬¬å››ä¸ªé€‚åˆå›ç­”è®¡ç®—æœºé—®é¢˜\n",
    "computerscience_template = \"\"\" ä½ æ˜¯ä¸€ä¸ªæˆåŠŸçš„è®¡ç®—æœºç§‘å­¦ä¸“å®¶ã€‚\\\n",
    "ä½ æœ‰åˆ›é€ åŠ›ã€åä½œç²¾ç¥ã€\\\n",
    "å‰ç»æ€§æ€ç»´ã€è‡ªä¿¡ã€è§£å†³é—®é¢˜çš„èƒ½åŠ›ã€\\\n",
    "å¯¹ç†è®ºå’Œç®—æ³•çš„ç†è§£ä»¥åŠå‡ºè‰²çš„æ²Ÿé€šæŠ€å·§ã€‚\\\n",
    "ä½ éå¸¸æ“…é•¿å›ç­”ç¼–ç¨‹é—®é¢˜ã€‚\\\n",
    "ä½ ä¹‹æ‰€ä»¥å¦‚æ­¤ä¼˜ç§€ï¼Œæ˜¯å› ä¸ºä½ çŸ¥é“  \\\n",
    "å¦‚ä½•é€šè¿‡ä»¥æœºå™¨å¯ä»¥è½»æ¾è§£é‡Šçš„å‘½ä»¤å¼æ­¥éª¤æè¿°è§£å†³æ–¹æ¡ˆæ¥è§£å†³é—®é¢˜ï¼Œ\\\n",
    "å¹¶ä¸”ä½ çŸ¥é“å¦‚ä½•é€‰æ‹©åœ¨æ—¶é—´å¤æ‚æ€§å’Œç©ºé—´å¤æ‚æ€§ä¹‹é—´å–å¾—è‰¯å¥½å¹³è¡¡çš„è§£å†³æ–¹æ¡ˆã€‚\n",
    "\n",
    "è¿™è¿˜æ˜¯ä¸€ä¸ªè¾“å…¥ï¼š\n",
    "{input}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "02431035-d3af-4744-bf63-9874296d18cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### ç›®æ ‡é“¾åç§°ã€æè¿°ã€æç¤ºæ¨¡æ¿\n",
    "prompt_infos = [\n",
    "    {\n",
    "        \"åå­—\": \"ç‰©ç†å­¦\",\n",
    "        \"æè¿°\": \"æ“…é•¿å›ç­”å…³äºç‰©ç†å­¦çš„é—®é¢˜\",\n",
    "        \"æç¤ºæ¨¡æ¿\": physics_template\n",
    "    },\n",
    "    {\n",
    "        \"åå­—\": \"æ•°å­¦\",\n",
    "        \"æè¿°\": \"æ“…é•¿å›ç­”æ•°å­¦é—®é¢˜\",\n",
    "        \"æç¤ºæ¨¡æ¿\": math_template\n",
    "    },\n",
    "    {\n",
    "        \"åå­—\": \"å†å²\",\n",
    "        \"æè¿°\": \"æ“…é•¿å›ç­”å†å²é—®é¢˜\",\n",
    "        \"æç¤ºæ¨¡æ¿\": history_template\n",
    "    },\n",
    "    {\n",
    "        \"åå­—\": \"è®¡ç®—æœºç§‘å­¦\",\n",
    "        \"æè¿°\": \"æ“…é•¿å›ç­”è®¡ç®—æœºç§‘å­¦é—®é¢˜\",\n",
    "        \"æç¤ºæ¨¡æ¿\": computerscience_template\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2a9b4c4a-8523-4b27-b617-ee110f29e4b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### æ„é€ ç›®æ ‡é“¾\n",
    "destination_chains = {}\n",
    "for p_info in prompt_infos:\n",
    "    name = p_info[\"åå­—\"]\n",
    "    prompt_template = p_info[\"æç¤ºæ¨¡æ¿\"]\n",
    "    prompt = ChatPromptTemplate.from_template(template=prompt_template)\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    destination_chains[name] = chain\n",
    "\n",
    "destinations = [f\"{p['åå­—']}: {p['æè¿°']}\" for p in prompt_infos]\n",
    "destinations_str = \"\\n\".join(destinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0847c55f-f229-45dc-93a1-2fec56651d50",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ç‰©ç†å­¦: æ“…é•¿å›ç­”å…³äºç‰©ç†å­¦çš„é—®é¢˜', 'æ•°å­¦: æ“…é•¿å›ç­”æ•°å­¦é—®é¢˜', 'å†å²: æ“…é•¿å›ç­”å†å²é—®é¢˜', 'è®¡ç®—æœºç§‘å­¦: æ“…é•¿å›ç­”è®¡ç®—æœºç§‘å­¦é—®é¢˜']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "destinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bed1dea9-707d-4741-8d4b-30cb2969ed9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### æ„é€ é»˜è®¤é“¾\n",
    "default_prompt = ChatPromptTemplate.from_template(\"{input}\")\n",
    "default_chain = LLMChain(llm=llm, prompt=default_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e9f7ea9f-d667-43a9-8ee4-a0faaa7aaacf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### å¤šæç¤ºè·¯ç”±æ¨¡æ¿\n",
    "MULTI_PROMPT_ROUTER_TEMPLATE = \"\"\"ç»™è¯­è¨€æ¨¡å‹ä¸€ä¸ªåŸå§‹æ–‡æœ¬è¾“å…¥ï¼Œ\\\n",
    "è®©å…¶é€‰æ‹©æœ€é€‚åˆè¾“å…¥çš„æ¨¡å‹æç¤ºã€‚\\\n",
    "ç³»ç»Ÿå°†ä¸ºæ‚¨æä¾›å¯ç”¨æç¤ºçš„åç§°ä»¥åŠæœ€é€‚åˆæ”¹æç¤ºçš„æè¿°ã€‚\\\n",
    "å¦‚æœä½ è®¤ä¸ºä¿®æ”¹åŸå§‹è¾“å…¥æœ€ç»ˆä¼šå¯¼è‡´è¯­è¨€æ¨¡å‹åšå‡ºæ›´å¥½çš„å“åº”ï¼Œ\\\n",
    "ä½ ä¹Ÿå¯ä»¥ä¿®æ”¹åŸå§‹è¾“å…¥ã€‚\n",
    "\n",
    "\n",
    "<< æ ¼å¼ >>\n",
    "è¿”å›ä¸€ä¸ªå¸¦æœ‰JSONå¯¹è±¡çš„markdownä»£ç ç‰‡æ®µï¼Œè¯¥JSONå¯¹è±¡çš„æ ¼å¼å¦‚ä¸‹ï¼š\n",
    "```json\n",
    "{{{{\n",
    "    \"destination\": å­—ç¬¦ä¸² \\ ä½¿ç”¨çš„æç¤ºåå­—æˆ–è€…ä½¿ç”¨ \"DEFAULT\"\n",
    "    \"next_inputs\": å­—ç¬¦ä¸² \\ åŸå§‹è¾“å…¥çš„æ”¹è¿›ç‰ˆæœ¬\n",
    "}}}}\n",
    "\n",
    "\n",
    "\n",
    "è®°ä½ï¼šâ€œdestinationâ€å¿…é¡»æ˜¯ä¸‹é¢æŒ‡å®šçš„å€™é€‰æç¤ºåç§°ä¹‹ä¸€ï¼Œ\\\n",
    "æˆ–è€…å¦‚æœè¾“å…¥ä¸å¤ªé€‚åˆä»»ä½•å€™é€‰æç¤ºï¼Œ\\\n",
    "åˆ™å¯ä»¥æ˜¯ â€œDEFAULTâ€ ã€‚\n",
    "è®°ä½ï¼šå¦‚æœæ‚¨è®¤ä¸ºä¸éœ€è¦ä»»ä½•ä¿®æ”¹ï¼Œ\\\n",
    "åˆ™ â€œnext_inputsâ€ å¯ä»¥åªæ˜¯åŸå§‹è¾“å…¥ã€‚\n",
    "\n",
    "<< å€™é€‰æç¤º >>\n",
    "{destinations}\n",
    "\n",
    "<< è¾“å…¥ >>\n",
    "{{input}}\n",
    "\n",
    "<< è¾“å‡º (è®°å¾—è¦åŒ…å« ```json)>>\n",
    "\n",
    "æ ·ä¾‹:\n",
    "<< è¾“å…¥ >>\n",
    "\"ä»€ä¹ˆæ˜¯é»‘ä½“è¾å°„?\"\n",
    "<< è¾“å‡º >>\n",
    "```json\n",
    "{{{{\n",
    "    \"destination\": å­—ç¬¦ä¸² \\ ä½¿ç”¨çš„æç¤ºåå­—æˆ–è€…ä½¿ç”¨ \"DEFAULT\"\n",
    "    \"next_inputs\": å­—ç¬¦ä¸² \\ åŸå§‹è¾“å…¥çš„æ”¹è¿›ç‰ˆæœ¬\n",
    "}}}}\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "47f7a525-0a9d-4074-a6b9-3d4e3c065624",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### æ„é€ è·¯ç”±é“¾\n",
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(\n",
    "    destinations=destinations_str\n",
    ")\n",
    "router_prompt = PromptTemplate(\n",
    "    template=router_template,\n",
    "    input_variables=[\"input\"],\n",
    "    output_parser=RouterOutputParser(),\n",
    ")\n",
    "\n",
    "router_chain = LLMRouterChain.from_llm(llm, router_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ab1e0720-c1d0-483d-8d27-c250fbc74880",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### æ•´ä½“è·¯ç”±é“¾\n",
    "chain = MultiPromptChain(router_chain=router_chain,  # è·¯ç”±é“¾\n",
    "              destination_chains=destination_chains,  # ç›®æ ‡é“¾\n",
    "              default_chain=default_chain,  # é»˜è®¤é“¾\n",
    "              verbose=True\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e69f8dfd-1b94-45e2-abcb-88be359cf3f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "None: {'input': 'ä½ å¥½'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ä½ å¥½ï¼ğŸ˜Š å¾ˆé«˜å…´è§åˆ°ä½ ï¼Œæœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®å¿™çš„å—ï¼Ÿ'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"ä½ å¥½\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ed3f35f9-d474-4282-98e1-e776656789f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "ç‰©ç†å­¦: {'input': 'ä½ èƒ½ä»‹ç»ä¸€ä¸‹ç‰›é¡¿çš„ä¸»è¦è´¡çŒ®å’Œä»–åœ¨ç‰©ç†å­¦ä¸­çš„åœ°ä½å—ï¼Ÿ'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'å½“ç„¶ï¼ç‰›é¡¿ï¼ˆIsaac Newtonï¼Œ1643â€“1727ï¼‰æ˜¯ç‰©ç†å­¦å²ä¸Šæœ€ä¼Ÿå¤§çš„ç§‘å­¦å®¶ä¹‹ä¸€ï¼Œä»–çš„è´¡çŒ®å¥ å®šäº†ç»å…¸ç‰©ç†å­¦çš„åŸºç¡€ã€‚ä»¥ä¸‹æ˜¯ä»–çš„æ ¸å¿ƒæˆå°±å’Œåœ°ä½ï¼š\\n\\n---\\n\\n### **ä¸»è¦è´¡çŒ®**\\n1. **ç‰›é¡¿è¿åŠ¨å®šå¾‹**  \\n   - **ç¬¬ä¸€å®šå¾‹ï¼ˆæƒ¯æ€§å®šå¾‹ï¼‰**ï¼šç‰©ä½“ä¿æŒé™æ­¢æˆ–åŒ€é€Ÿç›´çº¿è¿åŠ¨ï¼Œé™¤éå¤–åŠ›è¿«ä½¿å®ƒæ”¹å˜ã€‚  \\n   - **ç¬¬äºŒå®šå¾‹ï¼ˆF=maï¼‰**ï¼šåŠ›ä¸åŠ é€Ÿåº¦çš„å…³ç³»ã€‚  \\n   - **ç¬¬ä¸‰å®šå¾‹ï¼ˆä½œç”¨åŠ›ä¸åä½œç”¨åŠ›ï¼‰**ï¼šåŠ›çš„ç›¸äº’ä½œç”¨æ˜¯æˆå¯¹å‡ºç°çš„ã€‚  \\n   *æ„ä¹‰*ï¼šé¦–æ¬¡ç”¨æ•°å­¦æè¿°ç‰©ä½“è¿åŠ¨è§„å¾‹ï¼Œæˆä¸ºç»å…¸åŠ›å­¦çš„æ ¸å¿ƒã€‚\\n\\n2. **ä¸‡æœ‰å¼•åŠ›å®šå¾‹**  \\n   - æå‡ºä»»ä½•ä¸¤ä¸ªæœ‰è´¨é‡çš„ç‰©ä½“é—´å­˜åœ¨å¼•åŠ›ï¼ˆF=GÂ·mâ‚mâ‚‚/rÂ²ï¼‰ï¼Œç»Ÿä¸€è§£é‡Šäº†å¤©ä½“è¿åŠ¨ï¼ˆå¦‚è¡Œæ˜Ÿè½¨é“ï¼‰å’Œåœ°é¢ç‰©ä½“ï¼ˆå¦‚è‹¹æœä¸‹è½ï¼‰çš„åŠ›å­¦ç°è±¡ã€‚  \\n   *æ„ä¹‰*ï¼šå¼€åˆ›äº†å¤©ä½“åŠ›å­¦ï¼Œç›´æ¥æ¨åŠ¨äº†ç°ä»£å¤©æ–‡å­¦å‘å±•ã€‚\\n\\n3. **å¾®ç§¯åˆ†**ï¼ˆä¸è±å¸ƒå°¼èŒ¨ç‹¬ç«‹å‘å±•ï¼‰  \\n   - å‘æ˜æµæ•°æœ¯ï¼ˆå¾®ç§¯åˆ†çš„å‰èº«ï¼‰ï¼Œä¸ºç‰©ç†å­¦æä¾›äº†å…³é”®æ•°å­¦å·¥å…·ã€‚\\n\\n4. **å…‰å­¦ç ”ç©¶**  \\n   - å‘ç°ç™½å…‰ç”±å¤šç§è‰²å…‰ç»„æˆï¼ˆæ£±é•œå®éªŒï¼‰ï¼Œæå‡ºå…‰çš„â€œç²’å­è¯´â€ï¼ˆè™½ç„¶åç»­è¢«æ³¢åŠ¨è¯´è¡¥å……ï¼‰ã€‚  \\n   - å‘æ˜åå°„å¼æœ›è¿œé•œã€‚\\n\\n5. **å…¶ä»–**  \\n   - æå‡ºç»å¯¹æ—¶ç©ºè§‚ï¼ˆåè¢«çˆ±å› æ–¯å¦ç›¸å¯¹è®ºä¿®æ­£ï¼‰ï¼Œç ”ç©¶å£°é€Ÿã€æµä½“åŠ›å­¦ç­‰ã€‚\\n\\n---\\n\\n### **åœ¨ç‰©ç†å­¦ä¸­çš„åœ°ä½**\\n- **ç»å…¸åŠ›å­¦ä¹‹çˆ¶**ï¼šä»–çš„ã€Šè‡ªç„¶å“²å­¦çš„æ•°å­¦åŸç†ã€‹ï¼ˆ1687å¹´ï¼‰æ˜¯ç§‘å­¦å²ä¸Šæœ€ä¼Ÿå¤§çš„è‘—ä½œä¹‹ä¸€ï¼Œç³»ç»Ÿæ€§åœ°æ„å»ºäº†ç‰©ç†å­¦æ¡†æ¶ã€‚  \\n- **ç§‘å­¦é©å‘½å·…å³°**ï¼šå°†å®éªŒã€æ•°å­¦ä¸ç†è®ºç»“åˆï¼Œç¡®ç«‹äº†ç°ä»£ç§‘å­¦æ–¹æ³•è®ºã€‚  \\n- **å½±å“æ·±è¿œ**ï¼šç›´åˆ°19ä¸–çºªæœ«ï¼Œä»–çš„ç†è®ºä»æ˜¯ç‰©ç†å­¦çš„åŸºç¡€ï¼ˆé‡å­åŠ›å­¦å’Œç›¸å¯¹è®ºå‡ºç°åæ‰è¢«éƒ¨åˆ†ä¿®æ­£ï¼‰ã€‚\\n\\n---\\n\\n### **ç®€æ´æ€»ç»“**  \\nç‰›é¡¿ç”¨æ•°å­¦æ­ç¤ºäº†è‡ªç„¶çš„åŸºæœ¬è§„å¾‹ï¼Œå°†â€œå¤©ä¸Šâ€å’Œâ€œåœ°ä¸Šâ€çš„ç‰©ç†ç»Ÿä¸€èµ·æ¥ã€‚ä»–çš„å·¥ä½œä¸ä»…æ˜¯ç‰©ç†å­¦çš„åŸºçŸ³ï¼Œæ›´å½»åº•æ”¹å˜äº†äººç±»å¯¹å®‡å®™çš„è®¤çŸ¥ã€‚'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"ä½ äº†è§£ç‰›é¡¿\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ec01b2-3d6e-4417-b1f8-8d8cd9eceaad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myconda",
   "language": "python",
   "name": "myconda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
